{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class for preprocessing the ECoG data.\n",
    "\"\"\"\n",
    "\n",
    "class Preprocessor:\n",
    "    \n",
    "    \"\"\"\n",
    "    Init function. Takes data as given by FeatureDataHolder class, sets the bad indices and bad channels.\n",
    "    Input: Data, start and end in sample no. (not! seconds)\n",
    "    \"\"\"\n",
    "    def __init__(self,data=None,start_sample=0,end_sample=None):\n",
    "        self.data=data\n",
    "        self.start=start_sample\n",
    "        if end_sample is None:\n",
    "            self.end=data['dataset'].shape[1]-1\n",
    "        else:\n",
    "            self.end=end_sample\n",
    "        self.df=data['dataset'][:,start_sample:end_sample]\n",
    "        self.bad_idx=np.zeros(data['dataset'].shape[1],dtype='bool')\n",
    "        self.bad_chans=np.zeros(data['dataset'].shape[0],dtype='bool')\n",
    "        \n",
    "    #what do I want to filter??\n",
    "    #first, detect channels that are just flat signal\n",
    "    \"\"\"\n",
    "    Function to index the bad channels by super primitive techniques.\n",
    "    Input: Preferred filtering method (own vs. Steve's)\n",
    "    \"\"\"\n",
    "    def __bad_chan(self,prefiltered_sd_kurt=True):\n",
    "        unique_entr_per_chan=np.count_nonzero(np.diff(np.sort(self.df)), axis=1)+1\n",
    "        #which channels have only few entries? Throw away\n",
    "        self.bad_chans=unique_entr_per_chan<10\n",
    "        if(prefiltered_sd_kurt):\n",
    "            #convert the goodchan indices to a bad chan boolean mask\n",
    "            temp=np.ones(self.df.shape[0],dtype='bool')\n",
    "            temp[self.data['goodChanInds']]=False\n",
    "            self.bad_chans=np.logical_or(self.bad_chans,temp)\n",
    "        else:\n",
    "            all_std=self.data['SD_channels'][()]\n",
    "            std_std=np.std(all_std)\n",
    "            std_mean=np.mean(all_std)\n",
    "            too_high_std=all_std>std_mean+1.5*std_std\n",
    "            self.bad_chans=np.logical_or(self.bad_chans,too_high_std[0,:])\n",
    "           \n",
    "            \n",
    "    \"\"\"\n",
    "    Function to filter artifacts across all channels at certain time points.\n",
    "    \"\"\"\n",
    "    def __flat_sig(self):\n",
    "        #entries with high altitude? \n",
    "        self.bad_idx[np.array(self.data['allChanArtifactInds'][()][:],dtype=int)]=True\n",
    "        self.bad_idx=self.bad_idx[self.start:self.end] # these indices correspond to times starting from the beginning of recording. They need to be shifted so they match the 'new' beginning (start_sample)\n",
    "#this function \n",
    "\n",
    "    \"\"\"\n",
    "    Function to call both functions for preprocessing, one for channels, one for indices (see above)\n",
    "    Input: Which of the two we want\n",
    "    Output: The dataframe itself, in given time window (start and end time), indices of bad chans and bad indices\n",
    "    \"\"\"\n",
    "    def preprocess(self,prefiltered_sd_kurt=True,by_artifact=True):\n",
    "        self.__flat_sig()\n",
    "        self.__bad_chan(prefiltered_sd_kurt=prefiltered_sd_kurt)\n",
    "        return self.df, self.bad_chans,self.bad_idx\n",
    "        \n",
    "    \n",
    "#     #third, vals with too high of a variance are to be excluded. Note that varience is calculated without bad points\n",
    "#     #for excluding high vars, we calculate the variance of each channel, calc the std across these variances, exclude values \n",
    "#     #that are more than 2 std away\n",
    "#     def high_var(self):\n",
    "#         #next, let's look at variation changes per channel\n",
    "#         #get rid of points that are way off the mean\n",
    "#         vars_per_chan=[]\n",
    "#         for i in range(self.data.shape[0]):\n",
    "#             if self.bad_chans[i]!=True:\n",
    "#                 mean=np.mean(self.data[i,self.bad_idx[i]!=True])\n",
    "#                 std=np.std(self.data[i,self.bad_idx[i]!=True])\n",
    "#                 self.bad_idx[i]=np.logical_or(self.bad_idx[i],self.bad_idx[i]>mean+2*std)\n",
    "#                 vars_per_chan+=[std**2]\n",
    "#             else:\n",
    "#                 vars_per_chan+=[np.nan]\n",
    "#         #calc variance across time points that are OK\n",
    "#         var=np.array(vars_per_chan)\n",
    "#         #what is standart deviation and mean among the variances OF GOOD CHANNELS?\n",
    "#         varmean=np.nanmean(var[self.bad_chans!=True])\n",
    "#         varstd=np.std(var[self.bad_chans!=True])\n",
    "#         print(varmean,varstd)\n",
    "#         #get rid of avg that shoot way above. THESE ARE CHANNELS\n",
    "#         self.bad_var=var>varmean+1*varstd\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=h5py.File('/data2/users/stepeter/Preprocessing/processed_a0f66459_4.h5')\n",
    "# pr=Preprocessor(df,start_sample=11*500,end_sample=43205*500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat,tt,tw=pr.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dat.shape)\n",
    "# print(tt.shape)\n",
    "# tw.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(tw,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tt.shape)\n",
    "# print(tw.shape)\n",
    "# print(dat.shape)\n",
    "# aight=dat[tt!=True]\n",
    "# aight=aight[:,tw!=True]\n",
    "# print(aight.shape)\n",
    "# print(tw[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepr.bad_var.shape#print(np.unique(prepr.bad_idx,coun))\n",
    "\n",
    "# print(prepr.data[0].shape)\n",
    "# print(prepr.bad_idx.shape)\n",
    "# for p in range(0,127):\n",
    "#     if not prepr.bad_chans[p]: \n",
    "#         if not prepr.bad_var[p]:\n",
    "#             plt.plot(prepr.data[p,prepr.bad_idx[p]!=True])\n",
    "#     #mark bad points\n",
    "#     #plt.plot(np.arange(len(prepr.bad_idx[p]))[prepr.bad_idx[p]],np.zeros(len(prepr.bad_idx[p]))[prepr.bad_idx[p]]-.02, \"-\", markersize=1,)\n",
    "# plt.legend()\n",
    "\n",
    "# for p in range(0,127):\n",
    "#     if (bad_chans)\n",
    "#     plt.plot(prepr.data[p])\n",
    "\n",
    "# plt.plot(tt[0])\n",
    "# plt.plot(tt[1])\n",
    "# plt.plot(peaks, tt[1][peaks], \"x\")\n",
    "\n",
    "\n",
    "# np.random.seed(33)\n",
    "# test=np.random.uniform(0.9,1,(1,100))\n",
    "# print(test.shape)\n",
    "# test[0,10:20]=0\n",
    "# #test[1,15:25]=0\n",
    "# test[0,40:73]=0.95\n",
    "# #test[1,15:25]=0.95\n",
    "# #peaks=argrelextrema(test,np.less,order=25)\n",
    "# #plt.vlines(peaks,ymin=0, ymax=1)\n",
    "# #print(peaks)\n",
    "# grads=(np.gradient(test,axis=1)==0)\n",
    "# print(np.zeros(len(grads[p]))[grads[p]].shape)\n",
    "# for p in range(test.shape[0]):\n",
    "#     plt.plot(test[p])\n",
    "#     ym1 = np.ma.masked_where(grads[p] ==False , grads[p])\n",
    "#     plt.plot(np.arange(len(grads[p])),ym1-1.02, \"-\")\n",
    "\n",
    "# #np.argwhere(grads[1])[0]\n",
    "# #print(grads)\n",
    "# np.apply_along_axis(np.argwhere,1,grads)\n",
    "# np.argwhere(grads[2])\n",
    "# np.apply_along_axis(np.unique,1,grads)\n",
    "\n",
    "\n",
    "# ee=np.eye(3)\n",
    "# mask=np.zeros(ee.shape[0],dtype='bool')\n",
    "# mask[1]=True\n",
    "# mask[0]=True\n",
    "# #print(mask)\n",
    "\n",
    "# test=np.zeros(5)\n",
    "# np.logical_or(np.ones(5),test==1)\n",
    "\n",
    "\n",
    "# A=np.arange(5)\n",
    "# A[np.arange(2,3)]=False\n",
    "# print(A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
