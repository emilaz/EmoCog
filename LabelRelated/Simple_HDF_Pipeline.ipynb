{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file extracts data from the hdf files that contain the predictions coming from Gauthams OpenFace\n",
    "## It gets the raw Happy/Not Happy predictions per frame, per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import util.label_utils as util\n",
    "from datetime import time\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sess in [2,4,5,7,8,10,11]:\n",
    "    link='/home/emil/data/hdf_data/split_by_video/cb46fd46_'+str(sess)+'*.hdf'\n",
    "    rdd=dd.read_hdf(link,'/data')\n",
    "    #@TODO add realtime once available\n",
    "    imp_columns=['patient','success','frame','timestamp','annotated','confidence','session','vid','Happy_predicted','datetime','realtime']\n",
    "    df=rdd[imp_columns].compute()\n",
    "\n",
    "    #if success==False (i.e. could not detect AU), set happy pred to N/A\n",
    "    df.loc[df.success==0, 'Happy_predicted'] = float('NaN')\n",
    "\n",
    "    #sort by datetime and reset the indices\n",
    "    df.sort_values(by=['realtime'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    # def is_df_sorted(df, colname):\n",
    "    #     return pd.Index(df[colname]).is_monotonic\n",
    "\n",
    "    # is_df_sorted(df,'realtime')\n",
    "    link_save='/home/emil/data/hdf_data/cb46fd46_'+str(sess)+'_imp_columns.hdf'\n",
    "    df.to_hdf(link_save, key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath ='/home/emil/data/hdf_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = [f for f in listdir(mypath) if isfile(join(mypath, f)) and 'imp_columns' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,s in enumerate(sessions):\n",
    "    curr_df = pd.read_hdf(join(mypath,s))\n",
    "    if idx == 0:\n",
    "        df = curr_df\n",
    "    else:\n",
    "        df = df.append(curr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sort_values(by = ['datetime'])\n",
    "#df[df['session']=='11']\n",
    "df.drop('realtime', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('/nas/ecog_project/derived/processed_ecog/cb46fd46/full_day_ecog/vid_start_end_merge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "I want to order my hdf files not by session but by day. How?\n",
    "1. For each line of above df, create the videofile name.\n",
    "2. Find the corresponding time and day in the start_end_vid file\n",
    "3. Add to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_row(index,row):\n",
    "    #create the filename from line\n",
    "    #row = df_old.iloc[index]\n",
    "    pat = row['patient']\n",
    "    sess = row['session']\n",
    "    vid = row['vid']\n",
    "    fname = '_'.join([pat,sess,vid])\n",
    "    fname = '.'.join([fname,'avi'])\n",
    "    #find the file in the videotime infostuff\n",
    "    line = t[t['filename']==fname]\n",
    "    #crate time object\n",
    "    vid_time = time(line['hour'].iloc[0],line['minute'].iloc[0],line['second'].iloc[0],line['microsecond'].iloc[0])\n",
    "    #add column wih the important info\n",
    "    return [*row,vid_time,line['merge_day'].iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = df.iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(8)\n",
    "yass = pool.starmap(fill_row,all_rows)\n",
    "new_df = pd.DataFrame( yass, columns = [*df.columns,'steve_time','merge_day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in pd.unique(new_df['merge_day']):\n",
    "    curr_df = new_df[new_df['merge_day']==day]\n",
    "    sorted_curr_df = curr_df.sort_values(by=['session','vid','frame']).reset_index(drop=True)\n",
    "    sorted_curr_df.to_hdf('/home/emil/data/hdf_data/by_day/cb46fd46_day_'+str(day)+'.hdf',key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_hdf('/home/emil/data/hdf_data/by_day/cb46fd46_day_1.hdf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P3 emocog",
   "language": "python",
   "name": "emocog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
